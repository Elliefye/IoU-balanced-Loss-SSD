{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SSD.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPbUyhfXpJPh"
      },
      "source": [
        "Elina Fetingyte 1712325\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "SSD, IoU balanced loss, Human body/Horse/Knife\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qugO2k9eQkWf"
      },
      "source": [
        "Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aj5QM4HIQn-3"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from google.colab import drive"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iy0scquhQzJU"
      },
      "source": [
        "Import model from drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gO0DsWr3Q3Rg"
      },
      "source": [
        "# !rm -rf ./SSD/\n",
        "drive.mount('/content/drive')\n",
        "!mkdir model\n",
        "!cp ./drive/MyDrive/SSD/model* ./model/\n",
        "\n",
        "from model.ssd import SSD\n",
        "from model.utils import generate_dboxes, Encoder, colors\n",
        "from model.loss import Loss\n",
        "from model.process import train, evaluate\n",
        "from model.dataset import collate_fn, OIDataset\n",
        "from model.transform import SimpleTransformer"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enQujt-qSvrl"
      },
      "source": [
        "Set parameters for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LN6OwI-rSy34"
      },
      "source": [
        "epochs = 10\n",
        "batch_size = 4\n",
        "multistep = [5, 7]\n",
        "learning_rate = 2.6e-3\n",
        "mns_threshold = 0.5\n",
        "ioub_loss = True\n",
        "\n",
        "drive_path = '/content/drive/MyDrive/SSD'\n",
        "checkpoint_path = os.path.join(drive_path, \"/trained/SSD.pth\")\n",
        "log_path = os.path.join(drive_path, \"logs\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6RqrK3miSnh"
      },
      "source": [
        "Prepare data and model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUKj-LGciVAn"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    print('Will compute using CUDA')\n",
        "torch.cuda.manual_seed(123)\n",
        "\n",
        "train_params = {\"batch_size\": batch_size,\n",
        "                \"shuffle\": True,\n",
        "                \"drop_last\": False,\n",
        "                \"num_workers\": 4,\n",
        "                \"collate_fn\": collate_fn}\n",
        "\n",
        "test_params = {\"batch_size\": batch_size,\n",
        "               \"shuffle\": True,\n",
        "               \"drop_last\": False,\n",
        "               \"num_workers\": 4,\n",
        "               \"collate_fn\": collate_fn}\n",
        "            \n",
        "dboxes = generate_dboxes()\n",
        "model = SSD()\n",
        "train_set = OIDataset(SimpleTransformer(dboxes))\n",
        "train_loader = DataLoader(train_set, **train_params)\n",
        "test_set = OIDataset(SimpleTransformer(dboxes, eval=True), train=False)\n",
        "test_loader = DataLoader(test_set, **test_params)\n",
        "\n",
        "encoder = Encoder(dboxes)\n",
        "\n",
        "learning_rate = learning_rate * (batch_size / 32)\n",
        "criterion = Loss(dboxes, use_weighted_iou=ioub_loss)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9,\n",
        "                            weight_decay=0.0005,\n",
        "                            nesterov=True)\n",
        "scheduler = MultiStepLR(optimizer=optimizer, milestones=multistep, gamma=0.1)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "    criterion.cuda()\n",
        "\n",
        "model = torch.nn.DataParallel(model)\n",
        "writer = SummaryWriter(log_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2JjsHMbkZHH"
      },
      "source": [
        "Load checkpoint if possible"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA6-xtNJkbeT"
      },
      "source": [
        "if os.path.isfile(checkpoint_path):\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    first_epoch = checkpoint[\"epoch\"] + 1\n",
        "    model.module.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    scheduler.load_state_dict(checkpoint[\"scheduler\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "else:\n",
        "    first_epoch = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNygw5znkp80"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CccUjBIk6wy"
      },
      "source": [
        "for epoch in range(first_epoch, epochs):\n",
        "    train(model, train_loader, epoch, writer, criterion, optimizer, scheduler)\n",
        "    evaluate(model, test_loader, encoder, nms_threshold)\n",
        "\n",
        "    checkpoint = {\"epoch\": epoch,\n",
        "                  \"model_state_dict\": model.module.state_dict(),\n",
        "                  \"optimizer\": optimizer.state_dict(),\n",
        "                  \"scheduler\": scheduler.state_dict()}\n",
        "    torch.save(checkpoint, checkpoint_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-V2txynClzI4"
      },
      "source": [
        "Draw predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFaquNVLl19H"
      },
      "source": [
        "classes = ['Background', 'Knife', 'Horse', 'Human']\n",
        "cls_threshold = 0.3\n",
        "nms_threshold = 0.5\n",
        "model_path = f'{drive_path}/trained/SSD.pth'\n",
        "\n",
        "def ensure_legal(xmin, ymin, xmax, ymax, width, height):\n",
        "    if xmin < 0:\n",
        "        xmin = 0\n",
        "    if ymin < 0:\n",
        "        ymin = 0\n",
        "    if xmax > width:\n",
        "        xmax = width\n",
        "    if ymax > height:\n",
        "        ymax = height\n",
        "    return xmin, ymin, xmax, ymax\n",
        "\n",
        "\n",
        "def test_one(path):\n",
        "    model = SSD()\n",
        "    checkpoint = torch.load(model_path)\n",
        "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    if torch.cuda.is_available():\n",
        "        model.cuda()\n",
        "    model.eval()\n",
        "    dboxes = generate_dboxes()\n",
        "    transformer = SimpleTransformer(dboxes, eval=True)\n",
        "    img = Image.open(path).convert(\"RGB\")\n",
        "    img, _, _ = transformer(img, torch.zeros(4), torch.zeros(1))\n",
        "    encoder = Encoder(dboxes)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        img = img.cuda()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        ploc, plabel = model(img.unsqueeze(dim=0))\n",
        "        result = encoder.decode_batch(ploc, plabel, nms_threshold, 20)[0]\n",
        "        loc, label, prob = [r.cpu().numpy() for r in result]\n",
        "        best = np.argwhere(prob > cls_threshold).squeeze(axis=1)\n",
        "        loc = loc[best]\n",
        "        label = label[best]\n",
        "        prob = prob[best]\n",
        "        output_img = cv2.imread(path)\n",
        "\n",
        "        if len(loc) > 0:\n",
        "            height, width, _ = output_img.shape\n",
        "            loc[:, 0::2] *= width\n",
        "            loc[:, 1::2] *= height\n",
        "            loc = loc.astype(np.int32)\n",
        "\n",
        "            for box, lb, pr in zip(loc, label, prob):\n",
        "                category = classes[lb]\n",
        "                color = colors[lb]\n",
        "                xmin, ymin, xmax, ymax = box\n",
        "                xmin, ymin, xmax, ymax = ensure_legal(xmin, ymin, xmax, ymax, width, height)\n",
        "                cv2.rectangle(output_img, (xmin, ymin), (xmax, ymax), color, 2)\n",
        "                text_size = cv2.getTextSize(category + \" : %.2f\" % pr, cv2.FONT_HERSHEY_PLAIN, 1, 1)[0]\n",
        "                cv2.rectangle(output_img, (xmin, ymin), (xmin + text_size[0] + 3, ymin + text_size[1] + 4), color, -1)\n",
        "                cv2.putText(output_img, category + \" : %.2f\" % pr,\n",
        "                    (xmin, ymin + text_size[1] + 4), cv2.FONT_HERSHEY_PLAIN, 1,\n",
        "                    (255, 255, 255), 1)\n",
        "        cv2_imshow(output_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaBbBfHhnPOt"
      },
      "source": [
        "import random\n",
        "\n",
        "input_folder = f'{drive_path}/Dataset_lim/validation/horse/'\n",
        "for image in random.choices(os.listdir(input_folder), k=3):\n",
        "    test_one(input_folder + image)\n",
        "input_folder = f'{drive_path}/Dataset_lim/validation/human_body/'\n",
        "for image in random.choices(os.listdir(input_folder), k=3):\n",
        "    test_one(input_folder + image)\n",
        "input_folder = f'{drive_path}/Dataset_lim/validation/knife/'\n",
        "for image in random.choices(os.listdir(input_folder), k=3):\n",
        "    test_one(input_folder + image)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}